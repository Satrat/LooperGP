{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import json\n",
    "import random\n",
    "import dadagp\n",
    "import os\n",
    "from model_ead import TransformerXL\n",
    "import make_loops as loops\n",
    "import guitarpro\n",
    "import pickle\n",
    "import torch\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generates a folder of inferences attempts and runs the loop extraction algorithm on each of them. Also reports loop density statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILELIST_PATH = \"D:\\\\Documents\\\\DATA\\\\DadaGP-4-only-lps-3-dens-per-inst\\\\file_list_loops.json\" #list of files in loops dataset\n",
    "ROOT_PATH = \"D:\\\\Documents\\\\DATA\\\\DadaGP-4-only-lps-3-dens-per-inst\" #path to loops dataset\n",
    "OUTPUT_PATH = \"D:\\\\Documents\\\\DATA\\\\dadagp-generation-test\" #where to output generation results\n",
    "NUM_SAMPLES = 25 #how many excerpts generate\n",
    "LOOP_LENGTH = 4 #assumes all loops in FILELIST_PATH are this length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(FILELIST_PATH, \"r\") as f:\n",
    "    file_list =  json.load(f)\n",
    "num_files = len(file_list)\n",
    "print(\"{} files\".format(num_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomly sample tracks from the trainind data\n",
    "sampled_idxes = random.sample(range(num_files), NUM_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_sample_data = {}\n",
    "primers = []\n",
    "for id, idx in enumerate(sampled_idxes):\n",
    "    filepath = file_list[idx]\n",
    "    file = os.path.join(ROOT_PATH, file_list[idx])\n",
    "\n",
    "    with open(file, \"r\") as f:\n",
    "        text = f.read()\n",
    "    list_words = text.split(\"\\n\")\n",
    "\n",
    "    header_data = list_words[:4]\n",
    "    main_data = list_words[4:]\n",
    "\n",
    "    #calculate the number of loops in the song\n",
    "    num_measures = 0\n",
    "    measure_idx = []\n",
    "    for i,token in enumerate(main_data):\n",
    "        if token == \"new_measure\":\n",
    "            num_measures += 1\n",
    "            measure_idx.append(i)\n",
    "    num_segments = int(num_measures / LOOP_LENGTH)\n",
    "    measure_idx.append(len(main_data))\n",
    "\n",
    "    #choose a random loop in the song\n",
    "    rand_segment = random.randint(0, num_segments - 1)\n",
    "    human_sample_data[id] = rand_segment, filepath\n",
    "    measure_start = rand_segment * LOOP_LENGTH\n",
    "    start_idx = measure_idx[measure_start]\n",
    "    end_idx = measure_idx[measure_start + 4]\n",
    "\n",
    "    #use the first note of each instrument in the loop as a primer\n",
    "    final_loop = header_data + main_data[start_idx:end_idx]\n",
    "    if final_loop[-1] != \"end\":\n",
    "        final_loop.append(\"end\")\n",
    "    primer = []\n",
    "    for token in final_loop:\n",
    "        if \"artist:\" in token:\n",
    "            primer.append(\"artist:unknown_artist\")\n",
    "        else:\n",
    "            primer.append(token)\n",
    "        if \"wait:\" in token:\n",
    "            break\n",
    "    primers.append(primer)\n",
    "\n",
    "    #save the loop we took the primer from\n",
    "    token_path = os.path.join(OUTPUT_PATH, \"human\", \"ex_\" + str(id) + \".txt\")\n",
    "    dadagp_path = os.path.join(OUTPUT_PATH, \"human\", \"ex_\" + str(id) + \".gp5\")\n",
    "    file_out = open(token_path, \"w\")\n",
    "    file_out.write(\"\\n\".join(final_loop))\n",
    "    file_out.close()\n",
    "    dadagp.dadagp_decode(token_path, dadagp_path)\n",
    "\n",
    "#save a list of the primers\n",
    "path_json = os.path.join(OUTPUT_PATH, \"sampled_loops_info.json\")\n",
    "with open(path_json, 'w') as f:\n",
    "    json.dump(human_sample_data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the model\n",
    "cfg = yaml.full_load(open(\"../full-data-config_5_lat1024.yml\", 'r')) \n",
    "inferenceConfig = cfg['INFERENCE']\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = inferenceConfig['gpuID']\n",
    "\n",
    "CHECKPOINT_FOLDER = \"D:\\\\Documents\\\\Queen Mary\\\\dev\\\\msc_thesis\\\\dadaGP-generation\\\\model-weights\"\n",
    "EPOCH = 40\n",
    "NAME = \"ep_40\"\n",
    "model_path = os.path.join(CHECKPOINT_FOLDER, 'ep_{}.pth.tar'.format(str(EPOCH)))\n",
    "\n",
    "pretrainCfg = yaml.full_load(open(os.path.join(\"..\", CHECKPOINT_FOLDER,\"full-data-config.yml\"), 'r')) \n",
    "modelConfig = pretrainCfg['MODEL']\n",
    "\n",
    "event2word = pickle.load(open(os.path.join(\"..\", inferenceConfig['vocab_data_path']), 'rb'))\n",
    "word2event = pickle.load(open(os.path.join(\"..\", inferenceConfig['rev_vocab_data_path']), 'rb'))\n",
    "\n",
    "device = torch.device(\"cuda\" if not inferenceConfig[\"no_cuda\"] and torch.cuda.is_available() else \"cpu\")\n",
    "print('Device to generate:', device)\n",
    "\n",
    "model =  TransformerXL(\n",
    "        modelConfig,\n",
    "        inferenceConfig['gpuID'],\n",
    "        event2word=event2word, \n",
    "        word2event=word2event, \n",
    "        is_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate average number of notes per instrument in each measure\n",
    "def calc_density(token_list):\n",
    "    num_meas = 0\n",
    "    timestamp = 0\n",
    "    num_notes = {}\n",
    "    for i in range(len(token_list)):\n",
    "        t = token_list[i]\n",
    "        if \"note\" in t:\n",
    "            instrument = t.split(\":\")[0]\n",
    "            if instrument not in num_notes:\n",
    "                num_notes[instrument] = 1\n",
    "            else:\n",
    "                num_notes[instrument] += 1\n",
    "        if t == \"new_measure\":\n",
    "            num_meas += 1\n",
    "\n",
    "    total_notes = 0\n",
    "    for inst in num_notes.keys():\n",
    "        total_notes += num_notes[inst]\n",
    "    curr_density = total_notes * 1.0 / len(num_notes)\n",
    "\n",
    "    return curr_density / num_meas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop extraction parameters\n",
    "LOOP_SIZE = 4\n",
    "MIN_LEN = 4\n",
    "MIN_REP_BEATS = 2.0\n",
    "DENSITY = 1\n",
    "\n",
    "#generate NUM_BARS from each primer, keeping track of number of loops extracted and density\n",
    "NUM_BARS = 16\n",
    "total_segments = 0\n",
    "total_density = 0\n",
    "for idx, primer in enumerate(primers):\n",
    "    print(idx, primer)\n",
    "    generated = model.inference_single_from_primer(os.path.join(\"..\",model_path), ['temperature', 'nucleus'], {'t': 1.2 ,'p': 0.9, 'num_bars': NUM_BARS}, primer)\n",
    "\n",
    "    #save raw generation as GuitarPro file\n",
    "    song = dadagp.tokens2guitarpro(generated, verbose=False)\n",
    "    song.artist = generated[0]\n",
    "    song.album = 'Generated by DadaGP'\n",
    "    song.title = \"untitled\"\n",
    "    dadagp_path = os.path.join(OUTPUT_PATH, NAME, \"ex_\" + str(idx) + \"_full\" + \".gp5\")\n",
    "    guitarpro.write(song, dadagp_path)\n",
    "\n",
    "    #extract loops\n",
    "    track_list, time_signatures = loops.create_track_list(song)\n",
    "    beats_per_bar = 4 #inference forces 4/4\n",
    "    min_beats = beats_per_bar * LOOP_SIZE\n",
    "    max_beats = beats_per_bar * LOOP_SIZE\n",
    "    lead_mat, lead_dur, melody_seq = loops.calc_correlation(track_list, 0) \n",
    "    _, loop_endpoints = loops.get_valid_loops(melody_seq, lead_mat, lead_dur, min_len=MIN_LEN, min_beats=min_beats, max_beats=max_beats, min_rep_beats=MIN_REP_BEATS)\n",
    "    token_list = loops.unify_loops(generated, loop_endpoints, density=DENSITY)\n",
    "    token_list_repeats = loops.get_repeats(generated, min_meas=LOOP_SIZE, max_meas=LOOP_SIZE, density=DENSITY)\n",
    "    token_list = token_list + token_list_repeats\n",
    "    if token_list[-1] != \"end\":\n",
    "        token_list.append(\"end\")\n",
    "\n",
    "    loops_length = len(token_list)\n",
    "    if loops_length > 10:\n",
    "        header_data = token_list[:4]\n",
    "        main_data = token_list[4:]\n",
    "\n",
    "        num_measures = 0\n",
    "        split_loops = []\n",
    "        current_loop = []\n",
    "        for i,token in enumerate(main_data):\n",
    "            if token == \"new_measure\":\n",
    "                if num_measures > 0 and num_measures % LOOP_SIZE == 0: #end of a loop\n",
    "                    split_loops.append(current_loop)\n",
    "                    current_loop = []\n",
    "                num_measures += 1\n",
    "            if token == \"end\":\n",
    "                split_loops.append(current_loop)\n",
    "                break\n",
    "            current_loop.append(token)\n",
    "\n",
    "        token_list = header_data\n",
    "        \n",
    "        num_segments = 0\n",
    "        for i,loop in enumerate(split_loops):\n",
    "            duplicate = False\n",
    "            current = \" \". join(split_loops[i])\n",
    "            for j in range(0,i):\n",
    "                comparison = \" \".join(split_loops[j])\n",
    "                if comparison == current:\n",
    "                    duplicate = True\n",
    "                    break\n",
    "            if not duplicate:\n",
    "                token_list += loop\n",
    "                num_segments += 1\n",
    "        token_list.append(\"end\")\n",
    "\n",
    "        density = calc_density(token_list)\n",
    "        total_density += density\n",
    "        print(\"FOUND {} loops in ex_{}, density {}\".format(num_segments, idx, density))\n",
    "\n",
    "        #save extracted loops\n",
    "        song = dadagp.tokens2guitarpro(token_list, verbose=False)\n",
    "        song.artist = generated[0]\n",
    "        song.album = 'Generated by DadaGP'\n",
    "        song.title = \"untitled\"\n",
    "        dadagp_path = os.path.join(OUTPUT_PATH, NAME, \"ex_\" + str(idx) + \"_loops\" + \".gp5\")\n",
    "        guitarpro.write(song, dadagp_path)\n",
    "\n",
    "        total_segments += num_segments\n",
    "\n",
    "print(\"{} total loops {} avg loops {} avg density from {} primers\".format(total_segments, total_segments * 1.0 / len(primers), total_density / len(primers), len(primers)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad41e0d2c78ece94b277de777bb1902fc9e335e19d2884f562c7160c6a6d1eb4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
